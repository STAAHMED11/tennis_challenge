{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd6e9d6-5e91-45dc-ba3e-27a1dec2400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive features including temporal context.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # === BASIC CLEANING ===\n",
    "    df['x'] = df['x'].replace(0, np.nan).interpolate(method='cubic').bfill().ffill()\n",
    "    df['y'] = df['y'].replace(0, np.nan).interpolate(method='cubic').bfill().ffill()\n",
    "    \n",
    "    # === SMOOTHING ===\n",
    "    df['x_smooth'] = gaussian_filter1d(df['x'], sigma=1.5)\n",
    "    df['y_smooth'] = gaussian_filter1d(df['y'], sigma=1.5)\n",
    "    \n",
    "    # === VELOCITY ===\n",
    "    df['vx'] = df['x_smooth'].diff()\n",
    "    df['vy'] = df['y_smooth'].diff()\n",
    "    df['speed'] = np.sqrt(df['vx']**2 + df['vy']**2)\n",
    "    df['v_horizontal'] = df['vx'].abs()\n",
    "    df['v_vertical'] = df['vy'].abs()\n",
    "    \n",
    "    # === ACCELERATION ===\n",
    "    df['ax'] = df['vx'].diff()\n",
    "    df['ay'] = df['vy'].diff()\n",
    "    df['accel_magnitude'] = np.sqrt(df['ax']**2 + df['ay']**2)\n",
    "    df['accel_horizontal'] = df['ax'].abs()\n",
    "    df['accel_vertical'] = df['ay'].abs()\n",
    "    \n",
    "    # === JERK ===\n",
    "    df['jerk_x'] = df['ax'].diff()\n",
    "    df['jerk_y'] = df['ay'].diff()\n",
    "    df['jerk_magnitude'] = np.sqrt(df['jerk_x']**2 + df['jerk_y']**2)\n",
    "    \n",
    "    # === ANGLE CHANGE ===\n",
    "    df['angle'] = np.arctan2(df['vy'], df['vx'])\n",
    "    df['delta_angle'] = df['angle'].diff().abs()\n",
    "    df.loc[df['delta_angle'] > np.pi, 'delta_angle'] = \\\n",
    "        2*np.pi - df.loc[df['delta_angle'] > np.pi, 'delta_angle']\n",
    "    df['angular_velocity'] = df['delta_angle'] / (df['speed'] + 1e-6)\n",
    "    \n",
    "    # === VERTICAL VELOCITY ===\n",
    "    df['vy_change'] = df['vy'].diff()\n",
    "    df['vy_abs_change'] = df['vy_change'].abs()\n",
    "    df['vy_sign_change'] = ((df['vy'] * df['vy'].shift(1)) < 0).astype(int)\n",
    "    df['vy_acceleration'] = df['vy'].diff(2)\n",
    "    \n",
    "    # === HEIGHT & POSITION ===\n",
    "    max_y = df['y'].max()\n",
    "    min_y = df['y'].min()\n",
    "    y_range = max_y - min_y if (max_y - min_y) > 0 else 1\n",
    "    df['height_normalized'] = (max_y - df['y']) / y_range\n",
    "    df['height_raw'] = max_y - df['y']\n",
    "    \n",
    "    center_x = (df['x'].max() + df['x'].min()) / 2\n",
    "    df['dist_from_center'] = (df['x'] - center_x).abs()\n",
    "    \n",
    "    # === ENERGY & MOMENTUM ===\n",
    "    df['kinetic_energy'] = df['speed']**2\n",
    "    df['energy_change'] = df['kinetic_energy'].diff()\n",
    "    df['energy_change_rate'] = df['energy_change'] / (df['kinetic_energy'].shift(1) + 1e-6)\n",
    "    df['momentum_x'] = df['vx'] * df['speed']\n",
    "    df['momentum_y'] = df['vy'] * df['speed']\n",
    "    \n",
    "    # === CURVATURE ===\n",
    "    df['curvature'] = np.abs(df['ax'] * df['vy'] - df['ay'] * df['vx']) / \\\n",
    "                      (df['speed']**3 + 1e-6)\n",
    "    \n",
    "    # === ROLLING WINDOWS ===\n",
    "    for w in [3, 5, 7]:\n",
    "        df[f'speed_roll_mean_{w}'] = df['speed'].rolling(w, center=True).mean()\n",
    "        df[f'speed_roll_std_{w}'] = df['speed'].rolling(w, center=True).std()\n",
    "        df[f'speed_roll_max_{w}'] = df['speed'].rolling(w, center=True).max()\n",
    "        df[f'speed_roll_min_{w}'] = df['speed'].rolling(w, center=True).min()\n",
    "        df[f'accel_roll_mean_{w}'] = df['accel_magnitude'].rolling(w, center=True).mean()\n",
    "        df[f'accel_roll_max_{w}'] = df['accel_magnitude'].rolling(w, center=True).max()\n",
    "        df[f'jerk_roll_mean_{w}'] = df['jerk_magnitude'].rolling(w, center=True).mean()\n",
    "        df[f'jerk_roll_max_{w}'] = df['jerk_magnitude'].rolling(w, center=True).max()\n",
    "        df[f'vy_roll_std_{w}'] = df['vy'].rolling(w, center=True).std()\n",
    "        df[f'height_roll_std_{w}'] = df['height_normalized'].rolling(w, center=True).std()\n",
    "    \n",
    "    # === TEMPORAL CONTEXT: LAG FEATURES ===\n",
    "    temporal_features = ['speed', 'vx', 'vy', 'accel_magnitude', 'jerk_magnitude', \n",
    "                        'delta_angle', 'height_normalized', 'vy_change', 'kinetic_energy', 'curvature']\n",
    "    \n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for lag in [1, 2, 3, 5, 7]:\n",
    "            df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "            df[f'{feature}_diff_lag_{lag}'] = df[feature] - df[feature].shift(lag)\n",
    "            df[f'{feature}_ratio_lag_{lag}'] = df[feature] / (df[feature].shift(lag) + 1e-6)\n",
    "    \n",
    "    # === TEMPORAL CONTEXT: LEAD FEATURES ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for lead in [1, 2, 3, 5, 7]:\n",
    "            df[f'{feature}_lead_{lead}'] = df[feature].shift(-lead)\n",
    "            df[f'{feature}_diff_lead_{lead}'] = df[feature].shift(-lead) - df[feature]\n",
    "            df[f'{feature}_ratio_lead_{lead}'] = df[feature].shift(-lead) / (df[feature] + 1e-6)\n",
    "    \n",
    "    # === PAST WINDOW STATISTICS ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for window in [3, 5, 7, 10]:\n",
    "            df[f'{feature}_past_mean_{window}'] = df[feature].shift(1).rolling(window).mean()\n",
    "            df[f'{feature}_past_std_{window}'] = df[feature].shift(1).rolling(window).std()\n",
    "            df[f'{feature}_past_max_{window}'] = df[feature].shift(1).rolling(window).max()\n",
    "            df[f'{feature}_past_min_{window}'] = df[feature].shift(1).rolling(window).min()\n",
    "            df[f'{feature}_vs_past_{window}'] = df[feature] - df[f'{feature}_past_mean_{window}']\n",
    "    \n",
    "    # === FUTURE WINDOW STATISTICS ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for window in [3, 5, 7]:\n",
    "            df[f'{feature}_future_mean_{window}'] = df[feature].shift(-window).rolling(window).mean()\n",
    "            df[f'{feature}_future_std_{window}'] = df[feature].shift(-window).rolling(window).std()\n",
    "            df[f'{feature}_future_max_{window}'] = df[feature].shift(-window).rolling(window).max()\n",
    "            df[f'{feature}_future_min_{window}'] = df[feature].shift(-window).rolling(window).min()\n",
    "    \n",
    "    # === CENTERED WINDOW STATISTICS ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for window in [5, 7, 9, 11]:\n",
    "            df[f'{feature}_centered_mean_{window}'] = df[feature].rolling(window, center=True).mean()\n",
    "            df[f'{feature}_centered_std_{window}'] = df[feature].rolling(window, center=True).std()\n",
    "            df[f'{feature}_centered_range_{window}'] = \\\n",
    "                df[feature].rolling(window, center=True).max() - \\\n",
    "                df[feature].rolling(window, center=True).min()\n",
    "    \n",
    "    # === TEMPORAL DERIVATIVES ===\n",
    "    for feature in ['speed', 'accel_magnitude', 'height_normalized', 'delta_angle', 'jerk_magnitude']:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        df[f'{feature}_velocity'] = df[feature].diff()\n",
    "        df[f'{feature}_acceleration'] = df[f'{feature}_velocity'].diff()\n",
    "    \n",
    "    # === TREND FEATURES ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        for window in [5, 7, 10]:\n",
    "            df[f'{feature}_trend_{window}'] = df[feature].rolling(window, center=True).apply(\n",
    "                lambda x: np.polyfit(np.arange(len(x)), x, 1)[0] if len(x) == window else 0,\n",
    "                raw=True\n",
    "            )\n",
    "    \n",
    "    # === COMPARATIVE FEATURES (Past vs Future) ===\n",
    "    for feature in temporal_features:\n",
    "        if feature not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        window = 5\n",
    "        past_mean = df[feature].shift(1).rolling(window).mean()\n",
    "        future_mean = df[feature].shift(-window).rolling(window).mean()\n",
    "        \n",
    "        df[f'{feature}_past_vs_future'] = past_mean - future_mean\n",
    "        df[f'{feature}_is_peak'] = ((df[feature] > past_mean) & (df[feature] > future_mean)).astype(int)\n",
    "        df[f'{feature}_is_valley'] = ((df[feature] < past_mean) & (df[feature] < future_mean)).astype(int)\n",
    "    \n",
    "    # === TEMPORAL PATTERNS ===\n",
    "    df['speed_increasing'] = (df['speed'] > df['speed_lag_1']).astype(int)\n",
    "    df['speed_decreasing'] = (df['speed'] < df['speed_lag_1']).astype(int)\n",
    "    \n",
    "    df['height_rising'] = (df['height_normalized'] > df['height_normalized_lag_1']).astype(int)\n",
    "    df['height_falling'] = (df['height_normalized'] < df['height_normalized_lag_1']).astype(int)\n",
    "    \n",
    "    df['vy_reversed_recently'] = (\n",
    "        (df['vy'] * df['vy_lag_1'] < 0) |\n",
    "        (df['vy_lag_1'] * df['vy_lag_2'] < 0)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['vy_will_reverse'] = (\n",
    "        (df['vy'] * df['vy_lead_1'] < 0) |\n",
    "        (df['vy_lead_1'] * df['vy_lead_2'] < 0)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['vy_reversal_window'] = (\n",
    "        df['vy_reversed_recently'] | \n",
    "        df['vy_sign_change'] | \n",
    "        df['vy_will_reverse']\n",
    "    ).astype(int)\n",
    "    \n",
    "    # === SUSTAINED EVENTS ===\n",
    "    df['jerk_sustained_3'] = (\n",
    "        df['jerk_magnitude_past_max_3'] + \n",
    "        df['jerk_magnitude'] + \n",
    "        df['jerk_magnitude_future_max_3']\n",
    "    ) / 3\n",
    "    \n",
    "    df['accel_sustained_3'] = (\n",
    "        df['accel_magnitude_past_max_3'] + \n",
    "        df['accel_magnitude'] + \n",
    "        df['accel_magnitude_future_max_3']\n",
    "    ) / 3\n",
    "    \n",
    "    # === COMPOSITE FEATURES ===\n",
    "    df['impact_score'] = df['jerk_magnitude'] * df['accel_magnitude'] * df['delta_angle']\n",
    "    df['bounce_score'] = df['vy_sign_change'] * df['vy_change'] * (1 - df['height_normalized'])\n",
    "    df['vertical_impact'] = df['vy_abs_change'] * df['accel_vertical']\n",
    "    \n",
    "    # === PEAK DETECTION ===\n",
    "    from scipy.signal import find_peaks\n",
    "    \n",
    "    df['is_speed_peak'] = 0\n",
    "    df['is_accel_peak'] = 0\n",
    "    df['is_jerk_peak'] = 0\n",
    "    df['is_y_local_max'] = 0\n",
    "    df['is_y_local_min'] = 0\n",
    "    \n",
    "    if len(df) > 5:\n",
    "        speed_peaks, _ = find_peaks(df['speed'].values, distance=3)\n",
    "        accel_peaks, _ = find_peaks(df['accel_magnitude'].values, distance=3)\n",
    "        jerk_peaks, _ = find_peaks(df['jerk_magnitude'].values, distance=3)\n",
    "        y_maxs, _ = find_peaks(df['y_smooth'].values, distance=3, prominence=5)\n",
    "        y_mins, _ = find_peaks(-df['y_smooth'].values, distance=3, prominence=5)\n",
    "        \n",
    "        if len(speed_peaks) > 0:\n",
    "            df.iloc[speed_peaks, df.columns.get_loc('is_speed_peak')] = 1\n",
    "        if len(accel_peaks) > 0:\n",
    "            df.iloc[accel_peaks, df.columns.get_loc('is_accel_peak')] = 1\n",
    "        if len(jerk_peaks) > 0:\n",
    "            df.iloc[jerk_peaks, df.columns.get_loc('is_jerk_peak')] = 1\n",
    "        if len(y_maxs) > 0:\n",
    "            df.iloc[y_maxs, df.columns.get_loc('is_y_local_max')] = 1\n",
    "        if len(y_mins) > 0:\n",
    "            df.iloc[y_mins, df.columns.get_loc('is_y_local_min')] = 1\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. METHOD 1: PHYSICS-BASED THRESHOLD METHOD\n",
    "# ============================================================================\n",
    "\n",
    "def physics_method(df):\n",
    "    \"\"\"\n",
    "    Physics-based detection with optimized thresholds.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['pred_action'] = 'air'\n",
    "    \n",
    "    # Optimized thresholds\n",
    "    angle_threshold = 0.35\n",
    "    jerk_threshold = df['jerk_magnitude'].quantile(0.92)\n",
    "    accel_threshold = df['accel_magnitude'].quantile(0.88)\n",
    "    height_threshold = 0.25\n",
    "    min_speed = 3\n",
    "    \n",
    "    # Find candidates\n",
    "    candidates_mask = (\n",
    "        (df['delta_angle'] > angle_threshold) |\n",
    "        (df['jerk_magnitude'] > jerk_threshold) |\n",
    "        (df['accel_magnitude'] > accel_threshold)\n",
    "    ) & (df['speed'] > min_speed)\n",
    "    \n",
    "    candidates = df[candidates_mask]\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        return df\n",
    "    \n",
    "    # Classify BOUNCES\n",
    "    bounce_mask = (\n",
    "        (candidates['height_normalized'] < height_threshold) &\n",
    "        ((candidates['vy_sign_change'] == 1) | (candidates['vy_reversed_recently'] == 1)) &\n",
    "        (candidates['vy_change'] > candidates['vy_change'].quantile(0.4))\n",
    "    )\n",
    "    \n",
    "    bounce_indices = candidates[bounce_mask].index\n",
    "    df.loc[bounce_indices, 'pred_action'] = 'bounce'\n",
    "    \n",
    "    # Classify HITS\n",
    "    remaining = candidates[~candidates.index.isin(bounce_indices)]\n",
    "    hit_mask = (\n",
    "        (remaining['delta_angle'] > angle_threshold) |\n",
    "        (remaining['jerk_magnitude'] > jerk_threshold * 0.8)\n",
    "    )\n",
    "    \n",
    "    hit_indices = remaining[hit_mask].index\n",
    "    df.loc[hit_indices, 'pred_action'] = 'hit'\n",
    "    \n",
    "    # Post-processing\n",
    "    for action in ['hit', 'bounce']:\n",
    "        action_indices = df[df['pred_action'] == action].index.tolist()\n",
    "        for idx in action_indices:\n",
    "            window = df.iloc[max(0, idx-3):min(len(df), idx+4)]['pred_action']\n",
    "            if (window == action).sum() == 1:\n",
    "                df.at[idx, 'pred_action'] = 'air'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. METHOD 2: K-MEANS CLUSTERING WITH ALL FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "def kmeans_method(df):\n",
    "    \"\"\"\n",
    "    K-Means clustering using ALL features (no selection).\n",
    "    Clusters all frames into 3 classes: air, hit, bounce.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['pred_action'] = 'air'\n",
    "    \n",
    "    # Get ALL feature columns (exclude metadata and target)\n",
    "    exclude_cols = ['point_id', 'frame', 'x', 'y', 'x_smooth', 'y_smooth', \n",
    "                   'visible', 'action', 'pred_action', 'angle']\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    print(f\"  Using {len(feature_cols)} features for clustering\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df[feature_cols].values\n",
    "    \n",
    "    # Check for inf or nan values\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Standardize ALL features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Apply K-Means with 3 clusters (air, bounce, hit)\n",
    "    print(f\"  Applying K-Means with 3 clusters...\")\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=20, max_iter=300)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    df['cluster'] = clusters\n",
    "    \n",
    "    # Analyze cluster characteristics\n",
    "    print(f\"\\n  Cluster Analysis:\")\n",
    "    cluster_info = []\n",
    "    \n",
    "    for c in range(3):\n",
    "        cluster_data = df[df['cluster'] == c]\n",
    "        \n",
    "        info = {\n",
    "            'cluster': c,\n",
    "            'size': len(cluster_data),\n",
    "            'avg_height': cluster_data['height_normalized'].mean(),\n",
    "            'avg_angle': cluster_data['delta_angle'].mean(),\n",
    "            'avg_jerk': cluster_data['jerk_magnitude'].mean(),\n",
    "            'avg_speed': cluster_data['speed'].mean(),\n",
    "            'pct_vy_reversal': cluster_data['vy_sign_change'].mean(),\n",
    "            'pct_near_ground': (cluster_data['is_y_local_max'] == 1).mean(),\n",
    "            'avg_impact_score': cluster_data['impact_score'].mean(),\n",
    "            'avg_bounce_score': cluster_data['bounce_score'].mean()\n",
    "        }\n",
    "        cluster_info.append(info)\n",
    "        \n",
    "        print(f\"    Cluster {c}:\")\n",
    "        print(f\"      Size: {info['size']}\")\n",
    "        print(f\"      Avg Height: {info['avg_height']:.3f}\")\n",
    "        print(f\"      Avg Angle Change: {info['avg_angle']:.3f}\")\n",
    "        print(f\"      Avg Jerk: {info['avg_jerk']:.3f}\")\n",
    "        print(f\"      VY Reversal Rate: {info['pct_vy_reversal']:.3f}\")\n",
    "        print(f\"      Near Ground Rate: {info['pct_near_ground']:.3f}\")\n",
    "    \n",
    "    cluster_df = pd.DataFrame(cluster_info)\n",
    "    \n",
    "    # Assign clusters to actions based on characteristics\n",
    "    # BOUNCE: low height + high vy_reversal + near ground\n",
    "    bounce_score = (\n",
    "        (1 - cluster_df['avg_height']) * 3 +\n",
    "        cluster_df['pct_vy_reversal'] * 4 +\n",
    "        cluster_df['pct_near_ground'] * 3 +\n",
    "        cluster_df['avg_bounce_score'] * 2\n",
    "    )\n",
    "    bounce_cluster = bounce_score.idxmax()\n",
    "    \n",
    "    # HIT: high angle change + high jerk + high impact score\n",
    "    remaining_clusters = cluster_df[cluster_df['cluster'] != bounce_cluster]\n",
    "    \n",
    "    if len(remaining_clusters) > 0:\n",
    "        hit_score = (\n",
    "            remaining_clusters['avg_angle'] * 5 +\n",
    "            remaining_clusters['avg_jerk'] * 2 +\n",
    "            remaining_clusters['avg_impact_score'] * 3 +\n",
    "            (1 - remaining_clusters['pct_vy_reversal']) * 2\n",
    "        )\n",
    "        hit_cluster = remaining_clusters.iloc[hit_score.argmax()]['cluster']\n",
    "    else:\n",
    "        hit_cluster = None\n",
    "    \n",
    "    # AIR: the remaining cluster (typically largest, lowest activity)\n",
    "    air_cluster = [c for c in range(3) if c not in [bounce_cluster, hit_cluster]]\n",
    "    air_cluster = air_cluster[0] if air_cluster else None\n",
    "    \n",
    "    print(f\"\\n  Cluster → Action Assignment:\")\n",
    "    print(f\"    Cluster {bounce_cluster} → BOUNCE\")\n",
    "    print(f\"    Cluster {hit_cluster} → HIT\")\n",
    "    print(f\"    Cluster {air_cluster} → AIR\")\n",
    "    \n",
    "    # Apply predictions\n",
    "    for c in range(3):\n",
    "        indices = df[df['cluster'] == c].index\n",
    "        \n",
    "        if c == bounce_cluster:\n",
    "            df.loc[indices, 'pred_action'] = 'bounce'\n",
    "        elif c == hit_cluster:\n",
    "            df.loc[indices, 'pred_action'] = 'hit'\n",
    "        elif c == air_cluster:\n",
    "            df.loc[indices, 'pred_action'] = 'air'\n",
    "    \n",
    "    print(f\"\\n  Final Predictions:\")\n",
    "    print(f\"    Air: {(df['pred_action'] == 'air').sum()}\")\n",
    "    print(f\"    Bounces: {(df['pred_action'] == 'bounce').sum()}\")\n",
    "    print(f\"    Hits: {(df['pred_action'] == 'hit').sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_points(folder_path):\n",
    "    \"\"\"\n",
    "    Load all JSON files and process them.\n",
    "    \"\"\"\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    all_dfs = []\n",
    "    \n",
    "    print(f\"Loading {len(json_files)} points...\")\n",
    "    \n",
    "    for i, filename in enumerate(json_files):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Progress: {i+1}/{len(json_files)}\")\n",
    "        \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            point_data = json.load(f)\n",
    "        \n",
    "        frames = sorted(point_data.keys(), key=int)\n",
    "        rows = []\n",
    "        for f_idx in frames:\n",
    "            details = point_data[f_idx]\n",
    "            rows.append({\n",
    "                \"point_id\": filename.replace(\".json\", \"\"),\n",
    "                \"frame\": int(f_idx),\n",
    "                \"x\": details.get(\"x\"),\n",
    "                \"y\": details.get(\"y\"),\n",
    "                \"visible\": details.get(\"visible\"),\n",
    "                \"action\": details.get(\"action\")\n",
    "            })\n",
    "        \n",
    "        df_point = pd.DataFrame(rows)\n",
    "        df_point = calculate_advanced_features(df_point)\n",
    "        all_dfs.append(df_point)\n",
    "    \n",
    "    df_full = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nDataset loaded:\")\n",
    "    print(f\"  Total frames: {len(df_full)}\")\n",
    "    print(f\"  Total points: {df_full['point_id'].nunique()}\")\n",
    "    print(f\"  Total features: {len([c for c in df_full.columns if c not in ['point_id', 'frame', 'x', 'y', 'action']])}\")\n",
    "    \n",
    "    if 'action' in df_full.columns:\n",
    "        print(f\"\\nClass distribution:\")\n",
    "        print(df_full['action'].value_counts())\n",
    "    \n",
    "    return df_full\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_predictions(df, method_name):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation.\n",
    "    \"\"\"\n",
    "    if 'action' not in df.columns or df['action'].isna().all():\n",
    "        print(f\"{method_name}: No ground truth available\")\n",
    "        return None\n",
    "    \n",
    "    df_eval = df[df['action'].notna()].copy()\n",
    "    y_true = df_eval['action']\n",
    "    y_pred = df_eval['pred_action']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{method_name} - EVALUATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=['air', 'bounce', 'hit'])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"                Predicted\")\n",
    "    print(\"                air    bounce   hit\")\n",
    "    for i, label in enumerate(['air', 'bounce', 'hit']):\n",
    "        print(f\"True {label:8s}  {cm[i,0]:6d}  {cm[i,1]:6d}  {cm[i,2]:6d}\")\n",
    "    \n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nOverall Scores:\")\n",
    "    print(f\"  F1-Macro: {f1_macro:.4f}\")\n",
    "    print(f\"  F1-Weighted: {f1_weighted:.4f}\")\n",
    "    \n",
    "    return {'f1_macro': f1_macro, 'f1_weighted': f1_weighted, 'confusion_matrix': cm}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6265510-256b-44d6-a8ae-6d260f33392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HIT & BOUNCE DETECTION - UNSUPERVISED METHODS\n",
      "================================================================================\n",
      "Loading 313 points...\n",
      "  Progress: 50/313\n",
      "  Progress: 100/313\n",
      "  Progress: 150/313\n",
      "  Progress: 200/313\n",
      "  Progress: 250/313\n",
      "  Progress: 300/313\n",
      "\n",
      "Dataset loaded:\n",
      "  Total frames: 177341\n",
      "  Total points: 313\n",
      "  Total features: 889\n",
      "\n",
      "Class distribution:\n",
      "action\n",
      "air       174295\n",
      "hit         1600\n",
      "bounce      1446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "METHOD 1: PHYSICS-BASED THRESHOLDS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Physics-Based Method - EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air       0.99      0.91      0.95    174295\n",
      "      bounce       0.03      0.01      0.01      1446\n",
      "         hit       0.06      0.62      0.11      1600\n",
      "\n",
      "    accuracy                           0.90    177341\n",
      "   macro avg       0.36      0.51      0.36    177341\n",
      "weighted avg       0.98      0.90      0.94    177341\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted\n",
      "                air    bounce   hit\n",
      "True air       158917     248   15130\n",
      "True bounce       579       8     859\n",
      "True hit          605       6     989\n",
      "\n",
      "Overall Scores:\n",
      "  F1-Macro: 0.3554\n",
      "  F1-Weighted: 0.9352\n"
     ]
    }
   ],
   "source": [
    "FOLDER_PATH = \"per_point_v2\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HIT & BOUNCE DETECTION - UNSUPERVISED METHODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "df_full = load_all_points(FOLDER_PATH)\n",
    "\n",
    "# Method 1: Physics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD 1: PHYSICS-BASED THRESHOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "physics_results = []\n",
    "for point_id in df_full['point_id'].unique():\n",
    "    df_point = df_full[df_full['point_id'] == point_id].copy()\n",
    "    df_point = physics_method(df_point)\n",
    "    physics_results.append(df_point)\n",
    "\n",
    "df_physics = pd.concat(physics_results, ignore_index=True)\n",
    "results_physics = evaluate_predictions(df_physics, \"Physics-Based Method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878fea0-12dd-4725-b31a-6d8417720530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
